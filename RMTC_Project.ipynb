{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from keras.utils.np_utils import to_categorical\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# # from keras.layers.convolutional import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# # Replace 'model.p' with the path to your saved model file\n",
    "# model_path = 'D://Poorva//model_trained.keras'\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Parameters #####################\n",
    " \n",
    "path = \"C://Poorva//Poorva//myData\" # folder with all the class folders\n",
    "labelFile = 'C://Poorva//Poorva//labels.csv' # file with all names of classes\n",
    "batch_size_val=50  # how many to process together\n",
    "steps_per_epoch_val=2000\n",
    "epochs_val=10\n",
    "imageDimesions = (32,32,3)\n",
    "testRatio = 0.2    # if 1000 images split will 200 for testing\n",
    "validationRatio = 0.2 # if 1000 images 20% of remaining 800 will be 160 for validation\n",
    "###################################################\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes Detected: 43\n",
      "Importing Classes.....\n",
      "0 1 2 3 4 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Poorva\\Poorva\\RMTC_Project.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Poorva/Poorva/RMTC_Project.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m myPicList \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(count))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Poorva/Poorva/RMTC_Project.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m myPicList:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Poorva/Poorva/RMTC_Project.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     curImg \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(path\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(count)\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49my)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Poorva/Poorva/RMTC_Project.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     images\u001b[39m.\u001b[39mappend(curImg)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Poorva/Poorva/RMTC_Project.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     classNo\u001b[39m.\u001b[39mappend(count)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################### Importing of the Images\n",
    "count = 0\n",
    "images = []\n",
    "classNo = []\n",
    "myList = os.listdir(path)\n",
    "print(\"Total Classes Detected:\",len(myList))\n",
    "noOfClasses=len(myList)\n",
    "print(\"Importing Classes.....\")\n",
    "for x in range (0,len(myList)):\n",
    "    myPicList = os.listdir(path+\"/\"+str(count))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
    "        images.append(curImg)\n",
    "        classNo.append(count)\n",
    "    print(count, end =\" \")\n",
    "    count +=1\n",
    "print(\" \")\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)\n",
    " \n",
    "# X_train = ARRAY OF IMAGES TO TRAIN\n",
    "# y_train = CORRESPONDING CLASS ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TO CHECK IF NUMBER OF IMAGES MATCHES TO NUMBER OF LABELS FOR EACH DATA SET\n",
    "print(\"Data Shapes\")\n",
    "print(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\n",
    "print(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\n",
    "print(\"Test\",end = \"\");print(X_test.shape,y_test.shape)\n",
    "assert(X_train.shape[0]==y_train.shape[0]), \"The number of images in not equal to the number of lables in training set\"\n",
    "assert(X_validation.shape[0]==y_validation.shape[0]), \"The number of images in not equal to the number of lables in validation set\"\n",
    "assert(X_test.shape[0]==y_test.shape[0]), \"The number of images in not equal to the number of lables in test set\"\n",
    "assert(X_train.shape[1:]==(imageDimesions)),\" The dimesions of the Training images are wrong \"\n",
    "assert(X_validation.shape[1:]==(imageDimesions)),\" The dimesionas of the Validation images are wrong \"\n",
    "assert(X_test.shape[1:]==(imageDimesions)),\" The dimesionas of the Test images are wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### READ CSV FILE\n",
    "data=pd.read_csv(labelFile)\n",
    "print(\"data shape \",data.shape,type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### DISPLAY SOME SAMPLES IMAGES  OF ALL THE CLASSES\n",
    "num_of_samples = []\n",
    "cols = 5\n",
    "num_classes = noOfClasses\n",
    "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5, 300))\n",
    "fig.tight_layout()\n",
    "for i in range(cols):\n",
    "    for j,row in data.iterrows():\n",
    "        x_selected = X_train[y_train == j]\n",
    "        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected)- 1), :, :], cmap=plt.get_cmap(\"gray\"))\n",
    "        axs[j][i].axis(\"off\")\n",
    "        if i == 2:\n",
    "            axs[j][i].set_title(str(j)+ \"-\"+row[\"Name\"])\n",
    "            num_of_samples.append(len(x_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### DISPLAY A BAR CHART SHOWING NO OF SAMPLES FOR EACH CATEGORY\n",
    "print(num_of_samples)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(0, num_classes), num_of_samples)\n",
    "plt.title(\"Distribution of the training dataset\")\n",
    "plt.xlabel(\"Class number\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### PREPROCESSING THE IMAGES\n",
    " \n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "def equalize(img):\n",
    "    img =cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)     # CONVERT TO GRAYSCALE\n",
    "    img = equalize(img)      # STANDARDIZE THE LIGHTING IN AN IMAGE\n",
    "    img = img/255            # TO NORMALIZE VALUES BETWEEN 0 AND 1 INSTEAD OF 0 TO 255\n",
    "    return img\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(list(map(preprocessing,X_train)))  # TO IRETATE AND PREPROCESS ALL IMAGES\n",
    "X_validation=np.array(list(map(preprocessing,X_validation)))\n",
    "X_test=np.array(list(map(preprocessing,X_test)))\n",
    "cv2.imshow(\"GrayScale Images\",X_train[random.randint(0,len(X_train)-1)]) # TO CHECK IF THE TRAINING IS DONE PROPERLY\n",
    " \n",
    "############################### ADD A DEPTH OF 1\n",
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import special\n",
    "\n",
    "# Now you can use functions from the special module, like special.function_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### AUGMENTATAION OF IMAGES: TO MAKEIT MORE GENERIC\n",
    "dataGen= ImageDataGenerator(width_shift_range=0.1,   # 0.1 = 10%     IF MORE THAN 1 E.G 10 THEN IT REFFERS TO NO. OF  PIXELS EG 10 PIXELS\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,  # 0.2 MEANS CAN GO FROM 0.8 TO 1.2\n",
    "                            shear_range=0.1,  # MAGNITUDE OF SHEAR ANGLE\n",
    "                            rotation_range=10)  # DEGREES\n",
    "dataGen.fit(X_train)\n",
    "batches= dataGen.flow(X_train,y_train,batch_size=20)  # REQUESTING DATA GENRATOR TO GENERATE IMAGES  BATCH SIZE = NO. OF IMAGES CREAED EACH TIME ITS CALLED\n",
    "X_batch,y_batch = next(batches)\n",
    " \n",
    "# TO SHOW AGMENTED IMAGE SAMPLES\n",
    "fig,axs=plt.subplots(1,15,figsize=(20,5))\n",
    "fig.tight_layout()\n",
    " \n",
    "for i in range(15):\n",
    "    axs[i].imshow(X_batch[i].reshape(imageDimesions[0],imageDimesions[1]))\n",
    "    axs[i].axis('off')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_train = to_categorical(y_train,noOfClasses)\n",
    "y_validation = to_categorical(y_validation,noOfClasses)\n",
    "y_test = to_categorical(y_test,noOfClasses)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### CONVOLUTION NEURAL NETWORK MODEL\n",
    "def myModel():\n",
    "    no_Of_Filters=60\n",
    "    size_of_Filter=(5,5) # THIS IS THE KERNEL THAT MOVE AROUND THE IMAGE TO GET THE FEATURES.\n",
    "                         # THIS WOULD REMOVE 2 PIXELS FROM EACH BORDER WHEN USING 32 32 IMAGE\n",
    "    size_of_Filter2=(3,3)\n",
    "    size_of_pool=(2,2)  # SCALE DOWN ALL FEATURE MAP TO GERNALIZE MORE, TO REDUCE OVERFITTING\n",
    "    no_Of_Nodes = 500   # NO. OF NODES IN HIDDEN LAYERS\n",
    "    model= Sequential()\n",
    "    model.add((Conv2D(no_Of_Filters,size_of_Filter,input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n",
    "    model.add((Conv2D(no_Of_Filters, size_of_Filter, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=size_of_pool)) # DOES NOT EFFECT THE DEPTH/NO OF FILTERS\n",
    " \n",
    "    model.add((Conv2D(no_Of_Filters//2, size_of_Filter2,activation='relu')))\n",
    "    model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=size_of_pool))\n",
    "    model.add(Dropout(0.5))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_Of_Nodes,activation='relu'))\n",
    "    model.add(Dropout(0.5)) # INPUTS NODES TO DROP WITH EACH UPDATE 1 ALL 0 NONE\n",
    "    model.add(Dense(noOfClasses,activation='softmax')) # OUTPUT LAYER\n",
    "    # COMPILE MODEL\n",
    "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TRAIN\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "history=model.fit_generator(dataGen.flow(X_train,y_train,batch_size=batch_size_val),steps_per_epoch=steps_per_epoch_val,epochs=epochs_val,validation_data=(X_validation,y_validation),shuffle=1)\n",
    " \n",
    "############################### PLOT\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('Acurracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "score =model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Score:',score[0])\n",
    "print('Test Accuracy:',score[1])\n",
    " \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])  # for training accuracy\n",
    "plt.plot(history.history['val_accuracy'])  # for validation accuracy\n",
    "print(history.history.keys())\n",
    "print(history.history['loss'])\n",
    "print(history.history['accuracy'])\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORE THE MODEL AS A PICKLE OBJECT\n",
    "pickle_out= open(\"model_trained.p\",\"wb\")  # wb = WRITE BYTE\n",
    "pickle.dump(model,pickle_out)\n",
    "pickle_out.close()\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    " \n",
    "#############################################\n",
    " \n",
    "frameWidth= 640         # CAMERA RESOLUTION\n",
    "frameHeight = 480\n",
    "brightness = 180\n",
    "threshold = 0.75         # PROBABLITY THRESHOLD\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "##############################################\n",
    " \n",
    "# SETUP THE VIDEO CAMERA\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10, brightness)\n",
    "# IMPORT THE TRANNIED MODEL\n",
    "pickle_in=open(\"model_trained.p\",\"rb\")  ## rb = READ BYTE\n",
    "model=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "def equalize(img):\n",
    "    img =cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "def getCalssName(classNo):\n",
    "    if   classNo == 0: return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1: return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2: return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3: return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4: return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5: return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6: return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7: return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8: return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9: return 'No passing'\n",
    "    elif classNo == 10: return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11: return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12: return 'Priority road'\n",
    "    elif classNo == 13: return 'Yield'\n",
    "    elif classNo == 14: return 'Stop'\n",
    "    elif classNo == 15: return 'No vechiles'\n",
    "    elif classNo == 16: return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17: return 'No entry'\n",
    "    elif classNo == 18: return 'General caution'\n",
    "    elif classNo == 19: return 'Dangerous curve to the left'\n",
    "    elif classNo == 20: return 'Dangerous curve to the right'\n",
    "    elif classNo == 21: return 'Double curve'\n",
    "    elif classNo == 22: return 'Bumpy road'\n",
    "    elif classNo == 23: return 'Slippery road'\n",
    "    elif classNo == 24: return 'Road narrows on the right'\n",
    "    elif classNo == 25: return 'Road work'\n",
    "    elif classNo == 26: return 'Traffic signals'\n",
    "    elif classNo == 27: return 'Pedestrians'\n",
    "    elif classNo == 28: return 'Children crossing'\n",
    "    elif classNo == 29: return 'Bicycles crossing'\n",
    "    elif classNo == 30: return 'Beware of ice/snow'\n",
    "    elif classNo == 31: return 'Wild animals crossing'\n",
    "    elif classNo == 32: return 'End of all speed and passing limits'\n",
    "    elif classNo == 33: return 'Turn right ahead'\n",
    "    elif classNo == 34: return 'Turn left ahead'\n",
    "    elif classNo == 35: return 'Ahead only'\n",
    "    elif classNo == 36: return 'Go straight or right'\n",
    "    elif classNo == 37: return 'Go straight or left'\n",
    "    elif classNo == 38: return 'Keep right'\n",
    "    elif classNo == 39: return 'Keep left'\n",
    "    elif classNo == 40: return 'Roundabout mandatory'\n",
    "    elif classNo == 41: return 'End of no passing'\n",
    "    elif classNo == 42: return 'End of no passing by vechiles over 3.5 metric tons'\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    # READ IMAGE\n",
    "    success, imgOrignal = cap.read()\n",
    "    \n",
    "    # PROCESS IMAGE\n",
    "    img = np.asarray(imgOrignal)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = preprocessing(img)\n",
    "    cv2.imshow(\"Processed Image\", img)\n",
    "    img = img.reshape(1, 32, 32, 1)\n",
    "    cv2.putText(imgOrignal, \"CLASS: \" , (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(imgOrignal, \"PROBABILITY: \", (20, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    # PREDICT IMAGE\n",
    "    predictions = model.predict(img)\n",
    "    classIndex = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    probabilityValue =np.amax(predictions)\n",
    "    if probabilityValue > threshold:\n",
    "    #print(getCalssName(classIndex))\n",
    "        cv2.putText(imgOrignal,str(classIndex)+\" \"+str(getCalssName(classIndex)), (120, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(imgOrignal, str(round(probabilityValue*100,2) )+\"%\", (180, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"Result\", imgOrignal)\n",
    "    \n",
    "    if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMLSem1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
